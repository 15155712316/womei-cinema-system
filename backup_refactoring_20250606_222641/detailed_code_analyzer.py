#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PyQt5ç”µå½±ç¥¨åŠ¡ç®¡ç†ç³»ç»Ÿ - è¯¦ç»†ä»£ç åˆ†æå™¨
æ·±å…¥åˆ†æå…·ä½“çš„é‡å¤æ¨¡å¼å’Œä¼˜åŒ–æœºä¼š
"""

import os
import re
import ast
from pathlib import Path
from typing import Dict, List, Set, Tuple
from collections import defaultdict

class DetailedCodeAnalyzer:
    """è¯¦ç»†ä»£ç åˆ†æå™¨"""
    
    def __init__(self):
        self.main_file = "main_modular.py"
        self.analysis_results = {
            'api_patterns': [],
            'ui_patterns': [],
            'error_handling_patterns': [],
            'data_processing_patterns': [],
            'import_analysis': {},
            'method_complexity': [],
            'refactoring_opportunities': []
        }
    
    def analyze_main_program_patterns(self):
        """åˆ†æä¸»ç¨‹åºä¸­çš„é‡å¤æ¨¡å¼"""
        print("ğŸ” æ·±å…¥åˆ†æä¸»ç¨‹åºé‡å¤æ¨¡å¼...")
        
        if not Path(self.main_file).exists():
            return
        
        with open(self.main_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åˆ†æAPIè°ƒç”¨æ¨¡å¼
        self._analyze_api_patterns(content)
        
        # åˆ†æUIç»„ä»¶æ¨¡å¼
        self._analyze_ui_patterns(content)
        
        # åˆ†æé”™è¯¯å¤„ç†æ¨¡å¼
        self._analyze_error_handling_patterns(content)
        
        # åˆ†ææ•°æ®å¤„ç†æ¨¡å¼
        self._analyze_data_processing_patterns(content)
        
        # åˆ†æå¯¼å…¥ä½¿ç”¨æƒ…å†µ
        self._analyze_import_usage(content)
        
        print("âœ… ä¸»ç¨‹åºæ¨¡å¼åˆ†æå®Œæˆ")
    
    def _analyze_api_patterns(self, content: str):
        """åˆ†æAPIè°ƒç”¨æ¨¡å¼"""
        # æŸ¥æ‰¾APIè°ƒç”¨æ¨¡å¼
        api_patterns = [
            # requestsè°ƒç”¨æ¨¡å¼
            r'(requests\.(get|post|put|delete)\s*\([^)]+\))',
            # è‡ªå®šä¹‰APIè°ƒç”¨æ¨¡å¼
            r'(api_(get|post|put|delete)\s*\([^)]+\))',
            # æœåŠ¡è°ƒç”¨æ¨¡å¼
            r'(\w+_service\.\w+\([^)]*\))',
            # APIé”™è¯¯å¤„ç†æ¨¡å¼
            r'(try:\s*\n\s*.*?api.*?\n\s*except.*?:)',
        ]
        
        api_calls = []
        for pattern in api_patterns:
            matches = re.finditer(pattern, content, re.DOTALL | re.IGNORECASE)
            for match in matches:
                api_calls.append({
                    'pattern': pattern,
                    'call': match.group(1),
                    'start': match.start(),
                    'end': match.end()
                })
        
        # åˆ†ç»„ç›¸ä¼¼çš„APIè°ƒç”¨
        grouped_calls = self._group_similar_patterns(api_calls)
        self.analysis_results['api_patterns'] = grouped_calls
        
        print(f"  å‘ç° {len(api_calls)} ä¸ªAPIè°ƒç”¨ï¼Œ{len(grouped_calls)} ä¸ªæ¨¡å¼ç»„")
    
    def _analyze_ui_patterns(self, content: str):
        """åˆ†æUIç»„ä»¶æ¨¡å¼"""
        ui_patterns = [
            # PyQt5ç»„ä»¶åˆ›å»ºæ¨¡å¼
            r'(Q\w+\([^)]*\))',
            # å¸ƒå±€è®¾ç½®æ¨¡å¼
            r'(\w+\.setLayout\([^)]+\))',
            # æ ·å¼è®¾ç½®æ¨¡å¼
            r'(\w+\.setStyleSheet\([^)]+\))',
            # ä¿¡å·è¿æ¥æ¨¡å¼
            r'(\w+\.connect\([^)]+\))',
            # ç»„ä»¶æ·»åŠ æ¨¡å¼
            r'(\w+\.addWidget\([^)]+\))',
        ]
        
        ui_calls = []
        for pattern in ui_patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                ui_calls.append({
                    'pattern': pattern,
                    'call': match.group(1),
                    'start': match.start(),
                    'end': match.end()
                })
        
        grouped_ui = self._group_similar_patterns(ui_calls)
        self.analysis_results['ui_patterns'] = grouped_ui
        
        print(f"  å‘ç° {len(ui_calls)} ä¸ªUIè°ƒç”¨ï¼Œ{len(grouped_ui)} ä¸ªæ¨¡å¼ç»„")
    
    def _analyze_error_handling_patterns(self, content: str):
        """åˆ†æé”™è¯¯å¤„ç†æ¨¡å¼"""
        error_patterns = [
            # try-exceptæ¨¡å¼
            r'(try:\s*\n.*?\nexcept.*?:.*?\n)',
            # é”™è¯¯æ¶ˆæ¯æ˜¾ç¤ºæ¨¡å¼
            r'(QMessageBox\.(warning|critical|information)\([^)]+\))',
            # æ—¥å¿—è®°å½•æ¨¡å¼
            r'(print\(["\'].*?error.*?["\'][^)]*\))',
            # å¼‚å¸¸æŠ›å‡ºæ¨¡å¼
            r'(raise\s+\w+\([^)]*\))',
        ]
        
        error_calls = []
        for pattern in error_patterns:
            matches = re.finditer(pattern, content, re.DOTALL | re.IGNORECASE)
            for match in matches:
                error_calls.append({
                    'pattern': pattern,
                    'call': match.group(1),
                    'start': match.start(),
                    'end': match.end()
                })
        
        grouped_errors = self._group_similar_patterns(error_calls)
        self.analysis_results['error_handling_patterns'] = grouped_errors
        
        print(f"  å‘ç° {len(error_calls)} ä¸ªé”™è¯¯å¤„ç†ï¼Œ{len(grouped_errors)} ä¸ªæ¨¡å¼ç»„")
    
    def _analyze_data_processing_patterns(self, content: str):
        """åˆ†ææ•°æ®å¤„ç†æ¨¡å¼"""
        data_patterns = [
            # JSONå¤„ç†æ¨¡å¼
            r'(json\.(loads|dumps)\([^)]+\))',
            # å­—å…¸æ“ä½œæ¨¡å¼
            r'(\w+\.get\([^)]+\))',
            # åˆ—è¡¨æ“ä½œæ¨¡å¼
            r'(\[.*?for.*?in.*?\])',
            # å­—ç¬¦ä¸²æ ¼å¼åŒ–æ¨¡å¼
            r'(f["\'].*?\{.*?\}.*?["\'])',
            # æ•°æ®éªŒè¯æ¨¡å¼
            r'(if\s+\w+\s+is\s+(None|not\s+None))',
        ]
        
        data_calls = []
        for pattern in data_patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                data_calls.append({
                    'pattern': pattern,
                    'call': match.group(1),
                    'start': match.start(),
                    'end': match.end()
                })
        
        grouped_data = self._group_similar_patterns(data_calls)
        self.analysis_results['data_processing_patterns'] = grouped_data
        
        print(f"  å‘ç° {len(data_calls)} ä¸ªæ•°æ®å¤„ç†ï¼Œ{len(grouped_data)} ä¸ªæ¨¡å¼ç»„")
    
    def _analyze_import_usage(self, content: str):
        """åˆ†æå¯¼å…¥ä½¿ç”¨æƒ…å†µ"""
        # æå–æ‰€æœ‰å¯¼å…¥
        import_pattern = r'^(from\s+([\w.]+)\s+import\s+([\w,\s*]+)|import\s+([\w.,\s]+))'
        imports = re.findall(import_pattern, content, re.MULTILINE)
        
        import_usage = {}
        for imp in imports:
            if imp[1]:  # from ... import ...
                module = imp[1]
                items = [item.strip() for item in imp[2].split(',')]
                for item in items:
                    # è®¡ç®—ä½¿ç”¨æ¬¡æ•°
                    usage_count = len(re.findall(rf'\b{item}\b', content))
                    import_usage[f"{module}.{item}"] = usage_count
            elif imp[3]:  # import ...
                modules = [mod.strip() for mod in imp[3].split(',')]
                for module in modules:
                    usage_count = len(re.findall(rf'\b{module}\b', content))
                    import_usage[module] = usage_count
        
        # æ‰¾å‡ºæœªä½¿ç”¨æˆ–ä½ä½¿ç”¨çš„å¯¼å…¥
        unused_imports = {k: v for k, v in import_usage.items() if v <= 1}
        
        self.analysis_results['import_analysis'] = {
            'total_imports': len(import_usage),
            'unused_imports': unused_imports,
            'usage_stats': import_usage
        }
        
        print(f"  åˆ†æ {len(import_usage)} ä¸ªå¯¼å…¥ï¼Œ{len(unused_imports)} ä¸ªæœªä½¿ç”¨")
    
    def _group_similar_patterns(self, patterns: List[Dict]) -> List[Dict]:
        """å°†ç›¸ä¼¼çš„æ¨¡å¼åˆ†ç»„"""
        groups = []
        used_indices = set()
        
        for i, pattern1 in enumerate(patterns):
            if i in used_indices:
                continue
            
            group = [pattern1]
            used_indices.add(i)
            
            for j, pattern2 in enumerate(patterns[i+1:], i+1):
                if j in used_indices:
                    continue
                
                # ç®€å•çš„ç›¸ä¼¼æ€§æ£€æŸ¥
                if self._patterns_similar(pattern1['call'], pattern2['call']):
                    group.append(pattern2)
                    used_indices.add(j)
            
            if len(group) > 1:  # åªä¿ç•™æœ‰é‡å¤çš„ç»„
                groups.append({
                    'count': len(group),
                    'pattern_type': self._classify_pattern(group[0]['call']),
                    'examples': group[:3],  # åªä¿ç•™å‰3ä¸ªä¾‹å­
                    'refactoring_suggestion': self._suggest_refactoring(group)
                })
        
        return groups
    
    def _patterns_similar(self, pattern1: str, pattern2: str) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªæ¨¡å¼æ˜¯å¦ç›¸ä¼¼"""
        # ç§»é™¤å˜é‡åå’Œå…·ä½“å€¼ï¼Œåªä¿ç•™ç»“æ„
        normalized1 = re.sub(r'\b\w+\b', 'VAR', pattern1)
        normalized2 = re.sub(r'\b\w+\b', 'VAR', pattern2)
        
        # ç§»é™¤å­—ç¬¦ä¸²å’Œæ•°å­—
        normalized1 = re.sub(r'["\'].*?["\']', 'STR', normalized1)
        normalized2 = re.sub(r'["\'].*?["\']', 'STR', normalized2)
        normalized1 = re.sub(r'\d+', 'NUM', normalized1)
        normalized2 = re.sub(r'\d+', 'NUM', normalized2)
        
        return normalized1 == normalized2
    
    def _classify_pattern(self, pattern: str) -> str:
        """åˆ†ç±»æ¨¡å¼ç±»å‹"""
        if 'api' in pattern.lower() or 'request' in pattern.lower():
            return 'APIè°ƒç”¨'
        elif any(ui in pattern for ui in ['Q', 'Widget', 'Layout', 'Button']):
            return 'UIç»„ä»¶'
        elif 'except' in pattern or 'error' in pattern.lower():
            return 'é”™è¯¯å¤„ç†'
        elif 'json' in pattern.lower() or 'get(' in pattern:
            return 'æ•°æ®å¤„ç†'
        else:
            return 'å…¶ä»–'
    
    def _suggest_refactoring(self, group: List[Dict]) -> str:
        """å»ºè®®é‡æ„æ–¹æ¡ˆ"""
        pattern_type = self._classify_pattern(group[0]['call'])
        
        suggestions = {
            'APIè°ƒç”¨': 'æå–ä¸ºé€šç”¨APIè°ƒç”¨æ–¹æ³•ï¼Œç»Ÿä¸€é”™è¯¯å¤„ç†å’Œå‚æ•°éªŒè¯',
            'UIç»„ä»¶': 'åˆ›å»ºUIç»„ä»¶å·¥å‚ç±»ï¼Œç»Ÿä¸€ç»„ä»¶åˆ›å»ºå’Œæ ·å¼è®¾ç½®',
            'é”™è¯¯å¤„ç†': 'åˆ›å»ºç»Ÿä¸€çš„é”™è¯¯å¤„ç†è£…é¥°å™¨æˆ–åŸºç±»æ–¹æ³•',
            'æ•°æ®å¤„ç†': 'æå–ä¸ºæ•°æ®å¤„ç†å·¥å…·ç±»çš„é™æ€æ–¹æ³•',
            'å…¶ä»–': 'è€ƒè™‘æå–ä¸ºå…¬å…±å‡½æ•°æˆ–å¸¸é‡'
        }
        
        return suggestions.get(pattern_type, 'è€ƒè™‘æå–ä¸ºå…¬å…±å‡½æ•°')
    
    def analyze_method_complexity(self):
        """åˆ†ææ–¹æ³•å¤æ‚åº¦"""
        print("ğŸ” åˆ†ææ–¹æ³•å¤æ‚åº¦...")
        
        if not Path(self.main_file).exists():
            return
        
        with open(self.main_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–æ‰€æœ‰æ–¹æ³•
        method_pattern = r'def\s+(\w+)\s*\([^)]*\):\s*\n((?:\s{4,}.*\n)*)'
        methods = re.finditer(method_pattern, content, re.MULTILINE)
        
        complex_methods = []
        for match in methods:
            method_name = match.group(1)
            method_body = match.group(2)
            
            # è®¡ç®—å¤æ‚åº¦æŒ‡æ ‡
            lines = len([line for line in method_body.split('\n') if line.strip()])
            if_count = len(re.findall(r'\bif\b', method_body))
            for_count = len(re.findall(r'\bfor\b', method_body))
            try_count = len(re.findall(r'\btry\b', method_body))
            
            complexity_score = lines + if_count * 2 + for_count * 2 + try_count * 3
            
            if complexity_score > 50:  # å¤æ‚åº¦é˜ˆå€¼
                complex_methods.append({
                    'name': method_name,
                    'lines': lines,
                    'if_count': if_count,
                    'for_count': for_count,
                    'try_count': try_count,
                    'complexity_score': complexity_score,
                    'refactoring_suggestion': self._suggest_method_refactoring(complexity_score, lines)
                })
        
        self.analysis_results['method_complexity'] = complex_methods
        print(f"  å‘ç° {len(complex_methods)} ä¸ªå¤æ‚æ–¹æ³•éœ€è¦é‡æ„")
    
    def _suggest_method_refactoring(self, complexity: int, lines: int) -> str:
        """å»ºè®®æ–¹æ³•é‡æ„"""
        if lines > 100:
            return "æ–¹æ³•è¿‡é•¿ï¼Œå»ºè®®æ‹†åˆ†ä¸ºå¤šä¸ªå°æ–¹æ³•"
        elif complexity > 100:
            return "é€»è¾‘å¤æ‚ï¼Œå»ºè®®ä½¿ç”¨ç­–ç•¥æ¨¡å¼æˆ–çŠ¶æ€æ¨¡å¼"
        elif complexity > 70:
            return "å»ºè®®æå–éƒ¨åˆ†é€»è¾‘ä¸ºç§æœ‰æ–¹æ³•"
        else:
            return "å»ºè®®ç®€åŒ–æ¡ä»¶åˆ¤æ–­å’Œå¾ªç¯é€»è¾‘"
    
    def generate_refactoring_opportunities(self):
        """ç”Ÿæˆé‡æ„æœºä¼š"""
        print("ğŸ” ç”Ÿæˆé‡æ„æœºä¼š...")
        
        opportunities = []
        
        # APIæ¨¡å¼é‡æ„æœºä¼š
        api_groups = self.analysis_results.get('api_patterns', [])
        for group in api_groups:
            if group['count'] >= 3:
                opportunities.append({
                    'type': 'APIç»Ÿä¸€åŒ–',
                    'priority': 'high',
                    'description': f"å‘ç° {group['count']} ä¸ªç›¸ä¼¼çš„{group['pattern_type']}æ¨¡å¼",
                    'suggestion': group['refactoring_suggestion'],
                    'estimated_reduction': f"{group['count'] * 5} è¡Œä»£ç "
                })
        
        # UIæ¨¡å¼é‡æ„æœºä¼š
        ui_groups = self.analysis_results.get('ui_patterns', [])
        for group in ui_groups:
            if group['count'] >= 5:
                opportunities.append({
                    'type': 'UIç»„ä»¶åŒ–',
                    'priority': 'medium',
                    'description': f"å‘ç° {group['count']} ä¸ªç›¸ä¼¼çš„{group['pattern_type']}æ¨¡å¼",
                    'suggestion': group['refactoring_suggestion'],
                    'estimated_reduction': f"{group['count'] * 3} è¡Œä»£ç "
                })
        
        # é”™è¯¯å¤„ç†é‡æ„æœºä¼š
        error_groups = self.analysis_results.get('error_handling_patterns', [])
        for group in error_groups:
            if group['count'] >= 3:
                opportunities.append({
                    'type': 'é”™è¯¯å¤„ç†ç»Ÿä¸€åŒ–',
                    'priority': 'medium',
                    'description': f"å‘ç° {group['count']} ä¸ªç›¸ä¼¼çš„{group['pattern_type']}æ¨¡å¼",
                    'suggestion': group['refactoring_suggestion'],
                    'estimated_reduction': f"{group['count'] * 4} è¡Œä»£ç "
                })
        
        # å¤æ‚æ–¹æ³•é‡æ„æœºä¼š
        complex_methods = self.analysis_results.get('method_complexity', [])
        for method in complex_methods:
            opportunities.append({
                'type': 'æ–¹æ³•ç®€åŒ–',
                'priority': 'high' if method['complexity_score'] > 100 else 'medium',
                'description': f"æ–¹æ³• {method['name']} å¤æ‚åº¦è¿‡é«˜ ({method['complexity_score']})",
                'suggestion': method['refactoring_suggestion'],
                'estimated_reduction': f"{method['lines'] // 3} è¡Œä»£ç "
            })
        
        self.analysis_results['refactoring_opportunities'] = opportunities
        print(f"  ç”Ÿæˆ {len(opportunities)} ä¸ªé‡æ„æœºä¼š")
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸ¬ PyQt5ç”µå½±ç¥¨åŠ¡ç®¡ç†ç³»ç»Ÿ - è¯¦ç»†ä»£ç åˆ†æ")
        print("=" * 60)
        
        self.analyze_main_program_patterns()
        self.analyze_method_complexity()
        self.generate_refactoring_opportunities()
        
        return self.analysis_results

def main():
    """ä¸»å‡½æ•°"""
    analyzer = DetailedCodeAnalyzer()
    results = analyzer.run_analysis()
    
    # ä¿å­˜ç»“æœ
    import json
    with open('detailed_code_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # æ˜¾ç¤ºæ‘˜è¦
    print(f"\nğŸ“Š è¯¦ç»†åˆ†ææ‘˜è¦:")
    print(f"  APIæ¨¡å¼ç»„: {len(results.get('api_patterns', []))}")
    print(f"  UIæ¨¡å¼ç»„: {len(results.get('ui_patterns', []))}")
    print(f"  é”™è¯¯å¤„ç†æ¨¡å¼ç»„: {len(results.get('error_handling_patterns', []))}")
    print(f"  å¤æ‚æ–¹æ³•: {len(results.get('method_complexity', []))}")
    print(f"  é‡æ„æœºä¼š: {len(results.get('refactoring_opportunities', []))}")
    
    print(f"\nâœ… è¯¦ç»†ä»£ç åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: detailed_code_analysis.json")

if __name__ == "__main__":
    main()
