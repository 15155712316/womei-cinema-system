#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PyQt5ç”µå½±ç¥¨åŠ¡ç®¡ç†ç³»ç»Ÿ - ç¬¬ä¸‰é˜¶æ®µæ¶æ„ä¼˜åŒ–æ‰§è¡Œå™¨
åŸºäºç¬¬äºŒé˜¶æ®µæˆåŠŸå®Œæˆçš„é‡æ„åŸºç¡€ï¼Œè¿›è¡Œæ·±å±‚æ¬¡æ¶æ„ä¼˜åŒ–
"""

import os
import re
import ast
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional

class Phase3ArchitectureOptimizer:
    """ç¬¬ä¸‰é˜¶æ®µæ¶æ„ä¼˜åŒ–æ‰§è¡Œå™¨"""

    def __init__(self):
        self.main_file = "main_modular.py"
        self.backup_dir = f"backup_phase3_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.optimization_log = []
        self.analysis_results = {}

    def create_backup(self):
        """åˆ›å»ºç¬¬ä¸‰é˜¶æ®µå¤‡ä»½"""
        print("ğŸ“¦ åˆ›å»ºç¬¬ä¸‰é˜¶æ®µæ¶æ„ä¼˜åŒ–å¤‡ä»½...")

        try:
            os.makedirs(self.backup_dir, exist_ok=True)

            # å¤‡ä»½ä¸»æ–‡ä»¶å’Œå·¥å…·ç±»
            files_to_backup = [
                self.main_file,
                "ui/ui_component_factory.py",
                "utils/data_utils.py",
                "utils/error_handler.py"
            ]

            for file_path in files_to_backup:
                if Path(file_path).exists():
                    # ä¿æŒç›®å½•ç»“æ„
                    backup_path = Path(self.backup_dir) / file_path
                    backup_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(file_path, backup_path)

            print(f"âœ… å¤‡ä»½åˆ›å»ºæˆåŠŸ: {self.backup_dir}")
            return True

        except Exception as e:
            print(f"âŒ å¤‡ä»½åˆ›å»ºå¤±è´¥: {e}")
            return False

    def analyze_method_complexity(self):
        """åˆ†ææ–¹æ³•å¤æ‚åº¦"""
        print("ğŸ” åˆ†ææ–¹æ³•å¤æ‚åº¦...")

        if not Path(self.main_file).exists():
            return {}

        with open(self.main_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # è§£æAST
        try:
            tree = ast.parse(content)
        except SyntaxError as e:
            print(f"âŒ è¯­æ³•é”™è¯¯ï¼Œæ— æ³•è§£æ: {e}")
            return {}

        complex_methods = []

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # è®¡ç®—æ–¹æ³•å¤æ‚åº¦
                method_lines = node.end_lineno - node.lineno + 1

                # è®¡ç®—åœˆå¤æ‚åº¦æŒ‡æ ‡
                if_count = len([n for n in ast.walk(node) if isinstance(n, ast.If)])
                for_count = len([n for n in ast.walk(node) if isinstance(n, (ast.For, ast.While))])
                try_count = len([n for n in ast.walk(node) if isinstance(n, ast.Try)])

                complexity_score = method_lines + if_count * 2 + for_count * 2 + try_count * 3

                if method_lines > 50 or complexity_score > 30:  # å¤æ‚æ–¹æ³•é˜ˆå€¼
                    complex_methods.append({
                        'name': node.name,
                        'start_line': node.lineno,
                        'end_line': node.end_lineno,
                        'lines': method_lines,
                        'if_count': if_count,
                        'loop_count': for_count,
                        'try_count': try_count,
                        'complexity_score': complexity_score,
                        'priority': 'high' if complexity_score > 60 else 'medium'
                    })

        # æŒ‰å¤æ‚åº¦æ’åº
        complex_methods.sort(key=lambda x: x['complexity_score'], reverse=True)

        self.analysis_results['complex_methods'] = complex_methods

        print(f"  ğŸ“Š å‘ç°å¤æ‚æ–¹æ³•: {len(complex_methods)} ä¸ª")
        for method in complex_methods[:5]:  # æ˜¾ç¤ºå‰5ä¸ªæœ€å¤æ‚çš„
            print(f"    - {method['name']}: {method['lines']}è¡Œ, å¤æ‚åº¦{method['complexity_score']}")

        return complex_methods

    def analyze_api_patterns(self):
        """åˆ†æAPIè°ƒç”¨æ¨¡å¼"""
        print("ğŸ” åˆ†æAPIè°ƒç”¨æ¨¡å¼...")

        if not Path(self.main_file).exists():
            return {}

        with open(self.main_file, 'r', encoding='utf-8') as f:
            content = f.read()

        api_patterns = {
            'requests_calls': [],
            'api_endpoints': [],
            'error_handling': [],
            'response_parsing': []
        }

        # æŸ¥æ‰¾requestsè°ƒç”¨
        requests_pattern = r'requests\.(get|post|put|delete)\s*\([^)]*\)'
        for match in re.finditer(requests_pattern, content):
            line_num = content[:match.start()].count('\n') + 1
            api_patterns['requests_calls'].append({
                'method': match.group(1),
                'full_call': match.group(0),
                'line': line_num,
                'start': match.start(),
                'end': match.end()
            })

        # æŸ¥æ‰¾APIç«¯ç‚¹
        endpoint_pattern = r'[\'"]https?://[^\'\"]*[\'"]'
        for match in re.finditer(endpoint_pattern, content):
            line_num = content[:match.start()].count('\n') + 1
            api_patterns['api_endpoints'].append({
                'url': match.group(0),
                'line': line_num,
                'start': match.start(),
                'end': match.end()
            })

        # æŸ¥æ‰¾å“åº”è§£ææ¨¡å¼
        json_parse_pattern = r'\.json\(\)|json\.loads\([^)]*\)'
        for match in re.finditer(json_parse_pattern, content):
            line_num = content[:match.start()].count('\n') + 1
            api_patterns['response_parsing'].append({
                'pattern': match.group(0),
                'line': line_num,
                'start': match.start(),
                'end': match.end()
            })

        self.analysis_results['api_patterns'] = api_patterns

        print(f"  ğŸ“Š å‘ç°requestsè°ƒç”¨: {len(api_patterns['requests_calls'])} ä¸ª")
        print(f"  ğŸ“Š å‘ç°APIç«¯ç‚¹: {len(api_patterns['api_endpoints'])} ä¸ª")
        print(f"  ğŸ“Š å‘ç°å“åº”è§£æ: {len(api_patterns['response_parsing'])} ä¸ª")

        return api_patterns

    def analyze_design_patterns_opportunities(self):
        """åˆ†æè®¾è®¡æ¨¡å¼åº”ç”¨æœºä¼š"""
        print("ğŸ” åˆ†æè®¾è®¡æ¨¡å¼åº”ç”¨æœºä¼š...")

        if not Path(self.main_file).exists():
            return {}

        with open(self.main_file, 'r', encoding='utf-8') as f:
            content = f.read()

        pattern_opportunities = {
            'factory_pattern': [],
            'strategy_pattern': [],
            'observer_pattern': [],
            'singleton_pattern': []
        }

        # å·¥å‚æ¨¡å¼æœºä¼š - æŸ¥æ‰¾é‡å¤çš„å¯¹è±¡åˆ›å»º
        creation_patterns = [
            r'if\s+.*?==\s*[\'"](\w+)[\'"]:\s*\n\s*.*?=\s*(\w+)\(',
            r'payment_type\s*==\s*[\'"](\w+)[\'"]',
            r'order_type\s*==\s*[\'"](\w+)[\'"]'
        ]

        for pattern in creation_patterns:
            matches = re.finditer(pattern, content, re.MULTILINE)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                pattern_opportunities['factory_pattern'].append({
                    'type': match.group(1) if match.groups() else 'unknown',
                    'line': line_num,
                    'context': match.group(0)[:100]
                })

        # ç­–ç•¥æ¨¡å¼æœºä¼š - æŸ¥æ‰¾æ¡ä»¶åˆ†æ”¯
        strategy_pattern = r'if\s+.*?payment.*?:\s*\n.*?\nelse.*?:\s*\n'
        for match in re.finditer(strategy_pattern, content, re.MULTILINE | re.DOTALL):
            line_num = content[:match.start()].count('\n') + 1
            pattern_opportunities['strategy_pattern'].append({
                'line': line_num,
                'context': match.group(0)[:150]
            })

        # è§‚å¯Ÿè€…æ¨¡å¼æœºä¼š - æŸ¥æ‰¾çŠ¶æ€æ›´æ–°
        observer_patterns = [
            r'self\.\w+_status\s*=',
            r'update.*?ui',
            r'notify.*?change'
        ]

        for pattern in observer_patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                pattern_opportunities['observer_pattern'].append({
                    'line': line_num,
                    'pattern': match.group(0)
                })

        self.analysis_results['design_patterns'] = pattern_opportunities

        print(f"  ğŸ“Š å·¥å‚æ¨¡å¼æœºä¼š: {len(pattern_opportunities['factory_pattern'])} ä¸ª")
        print(f"  ğŸ“Š ç­–ç•¥æ¨¡å¼æœºä¼š: {len(pattern_opportunities['strategy_pattern'])} ä¸ª")
        print(f"  ğŸ“Š è§‚å¯Ÿè€…æ¨¡å¼æœºä¼š: {len(pattern_opportunities['observer_pattern'])} ä¸ª")

        return pattern_opportunities

    def analyze_performance_bottlenecks(self):
        """åˆ†ææ€§èƒ½ç“¶é¢ˆ"""
        print("ğŸ” åˆ†ææ€§èƒ½ç“¶é¢ˆ...")

        if not Path(self.main_file).exists():
            return {}

        with open(self.main_file, 'r', encoding='utf-8') as f:
            content = f.read()

        performance_issues = {
            'repeated_calculations': [],
            'inefficient_loops': [],
            'memory_leaks': [],
            'blocking_operations': []
        }

        # æŸ¥æ‰¾é‡å¤è®¡ç®—
        calc_patterns = [
            r'for\s+\w+\s+in\s+\w+:\s*\n\s*.*?calculate.*?\(',
            r'len\([^)]+\)\s*>\s*0',
            r'\.get\([^)]+\)\s*is\s+not\s+None'
        ]

        for pattern in calc_patterns:
            matches = re.finditer(pattern, content, re.MULTILINE)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                performance_issues['repeated_calculations'].append({
                    'line': line_num,
                    'pattern': match.group(0),
                    'suggestion': 'è€ƒè™‘ç¼“å­˜è®¡ç®—ç»“æœ'
                })

        # æŸ¥æ‰¾ä½æ•ˆå¾ªç¯
        loop_patterns = [
            r'for\s+\w+\s+in\s+range\(len\([^)]+\)\):',
            r'while\s+.*?:\s*\n\s*.*?sleep\('
        ]

        for pattern in loop_patterns:
            matches = re.finditer(pattern, content, re.MULTILINE)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                performance_issues['inefficient_loops'].append({
                    'line': line_num,
                    'pattern': match.group(0),
                    'suggestion': 'ä¼˜åŒ–å¾ªç¯é€»è¾‘'
                })

        # æŸ¥æ‰¾é˜»å¡æ“ä½œ
        blocking_patterns = [
            r'requests\.(get|post)\([^)]*\)',
            r'time\.sleep\([^)]*\)',
            r'input\([^)]*\)'
        ]

        for pattern in blocking_patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                line_num = content[:match.start()].count('\n') + 1
                performance_issues['blocking_operations'].append({
                    'line': line_num,
                    'operation': match.group(0),
                    'suggestion': 'è€ƒè™‘å¼‚æ­¥å¤„ç†'
                })

        self.analysis_results['performance_issues'] = performance_issues

        total_issues = sum(len(issues) for issues in performance_issues.values())
        print(f"  ğŸ“Š å‘ç°æ€§èƒ½é—®é¢˜: {total_issues} ä¸ª")

        return performance_issues

    def run_comprehensive_analysis(self):
        """è¿è¡Œç»¼åˆåˆ†æ"""
        print("ğŸš€ å¼€å§‹ç¬¬ä¸‰é˜¶æ®µç»¼åˆåˆ†æ")
        print("=" * 60)

        # åˆ›å»ºå¤‡ä»½
        if not self.create_backup():
            return False

        # æ‰§è¡Œå„é¡¹åˆ†æ
        self.analyze_method_complexity()
        self.analyze_api_patterns()
        self.analyze_design_patterns_opportunities()
        self.analyze_performance_bottlenecks()

        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self.generate_analysis_report()

        print("\nâœ… ç¬¬ä¸‰é˜¶æ®µç»¼åˆåˆ†æå®Œæˆï¼")
        return True

    def generate_analysis_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("ğŸ“Š ç”Ÿæˆç¬¬ä¸‰é˜¶æ®µåˆ†ææŠ¥å‘Š...")

        report = f"""# PyQt5ç”µå½±ç¥¨åŠ¡ç®¡ç†ç³»ç»Ÿ - ç¬¬ä¸‰é˜¶æ®µæ¶æ„ä¼˜åŒ–åˆ†ææŠ¥å‘Š

## ğŸ“Š åˆ†ææ¦‚è§ˆ

**åˆ†ææ—¶é—´**ï¼š{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}
**åˆ†æé˜¶æ®µ**ï¼šç¬¬ä¸‰é˜¶æ®µ - æ¶æ„ä¼˜åŒ–
**å¤‡ä»½ç›®å½•**ï¼š{self.backup_dir}

---

## ğŸ” å¤æ‚æ–¹æ³•åˆ†æ

### å‘ç°çš„å¤æ‚æ–¹æ³•
"""

        complex_methods = self.analysis_results.get('complex_methods', [])
        if complex_methods:
            for method in complex_methods:
                report += f"""
#### {method['name']} (ç¬¬{method['start_line']}-{method['end_line']}è¡Œ)
- **ä»£ç è¡Œæ•°**ï¼š{method['lines']} è¡Œ
- **å¤æ‚åº¦è¯„åˆ†**ï¼š{method['complexity_score']}
- **æ¡ä»¶åˆ†æ”¯**ï¼š{method['if_count']} ä¸ª
- **å¾ªç¯ç»“æ„**ï¼š{method['loop_count']} ä¸ª
- **å¼‚å¸¸å¤„ç†**ï¼š{method['try_count']} ä¸ª
- **ä¼˜åŒ–ä¼˜å…ˆçº§**ï¼š{method['priority']}
- **å»ºè®®**ï¼šæ‹†åˆ†ä¸ºå¤šä¸ªèŒè´£å•ä¸€çš„å°æ–¹æ³•
"""
        else:
            report += "\nâœ… æœªå‘ç°éœ€è¦æ‹†åˆ†çš„å¤æ‚æ–¹æ³•\n"

        report += f"""
---

## ğŸŒ APIè°ƒç”¨æ¨¡å¼åˆ†æ

### APIè°ƒç”¨ç»Ÿè®¡
"""

        api_patterns = self.analysis_results.get('api_patterns', {})
        report += f"""
- **Requestsè°ƒç”¨**ï¼š{len(api_patterns.get('requests_calls', []))} ä¸ª
- **APIç«¯ç‚¹**ï¼š{len(api_patterns.get('api_endpoints', []))} ä¸ª
- **å“åº”è§£æ**ï¼š{len(api_patterns.get('response_parsing', []))} ä¸ª

### ç»Ÿä¸€åŒ–å»ºè®®
1. **åˆ›å»ºç»Ÿä¸€APIå®¢æˆ·ç«¯**ï¼šé›†ä¸­ç®¡ç†æ‰€æœ‰APIè°ƒç”¨
2. **æ ‡å‡†åŒ–é”™è¯¯å¤„ç†**ï¼šç»Ÿä¸€çš„å¼‚å¸¸å¤„ç†å’Œé‡è¯•æœºåˆ¶
3. **å“åº”è§£æç»Ÿä¸€**ï¼šæ ‡å‡†åŒ–çš„å“åº”æ•°æ®å¤„ç†
"""

        report += f"""
---

## ğŸ¨ è®¾è®¡æ¨¡å¼åº”ç”¨æœºä¼š

### æ¨¡å¼åº”ç”¨å»ºè®®
"""

        design_patterns = self.analysis_results.get('design_patterns', {})
        report += f"""
- **å·¥å‚æ¨¡å¼æœºä¼š**ï¼š{len(design_patterns.get('factory_pattern', []))} ä¸ª
- **ç­–ç•¥æ¨¡å¼æœºä¼š**ï¼š{len(design_patterns.get('strategy_pattern', []))} ä¸ª
- **è§‚å¯Ÿè€…æ¨¡å¼æœºä¼š**ï¼š{len(design_patterns.get('observer_pattern', []))} ä¸ª

### å…·ä½“åº”ç”¨å»ºè®®
1. **æ”¯ä»˜å¤„ç†å·¥å‚**ï¼šç»Ÿä¸€æ”¯ä»˜æ–¹å¼åˆ›å»º
2. **è®¢å•çŠ¶æ€ç­–ç•¥**ï¼šä¸åŒè®¢å•çŠ¶æ€çš„å¤„ç†ç­–ç•¥
3. **UIæ›´æ–°è§‚å¯Ÿè€…**ï¼šçŠ¶æ€å˜åŒ–çš„UIè‡ªåŠ¨æ›´æ–°
"""

        report += f"""
---

## âš¡ æ€§èƒ½ä¼˜åŒ–æœºä¼š

### æ€§èƒ½é—®é¢˜ç»Ÿè®¡
"""

        performance_issues = self.analysis_results.get('performance_issues', {})
        total_perf_issues = sum(len(issues) for issues in performance_issues.values())

        report += f"""
- **é‡å¤è®¡ç®—**ï¼š{len(performance_issues.get('repeated_calculations', []))} ä¸ª
- **ä½æ•ˆå¾ªç¯**ï¼š{len(performance_issues.get('inefficient_loops', []))} ä¸ª
- **é˜»å¡æ“ä½œ**ï¼š{len(performance_issues.get('blocking_operations', []))} ä¸ª
- **æ€»è®¡é—®é¢˜**ï¼š{total_perf_issues} ä¸ª

### ä¼˜åŒ–å»ºè®®
1. **è®¡ç®—ç»“æœç¼“å­˜**ï¼šé¿å…é‡å¤è®¡ç®—
2. **å¾ªç¯ä¼˜åŒ–**ï¼šä½¿ç”¨æ›´é«˜æ•ˆçš„è¿­ä»£æ–¹å¼
3. **å¼‚æ­¥å¤„ç†**ï¼šé¿å…é˜»å¡ä¸»çº¿ç¨‹
4. **å†…å­˜ç®¡ç†**ï¼šä¼˜åŒ–å¯¹è±¡åˆ›å»ºå’Œé”€æ¯
"""

        report += f"""
---

## ğŸ¯ ç¬¬ä¸‰é˜¶æ®µæ‰§è¡Œè®¡åˆ’

### ç¬¬ä¸‰é˜¶æ®µAï¼šå¤æ‚æ–¹æ³•æ‹†åˆ† (2-3å¤©)
- **ç›®æ ‡**ï¼šæ‹†åˆ†{len(complex_methods)}ä¸ªå¤æ‚æ–¹æ³•
- **é¢„æœŸæ”¶ç›Š**ï¼šä»£ç å¯è¯»æ€§æå‡60-80%
- **é£é™©ç­‰çº§**ï¼šä¸­ç­‰

### ç¬¬ä¸‰é˜¶æ®µBï¼šAPIè°ƒç”¨ç»Ÿä¸€åŒ– (2-3å¤©)
- **ç›®æ ‡**ï¼šç»Ÿä¸€{len(api_patterns.get('requests_calls', []))}ä¸ªAPIè°ƒç”¨
- **é¢„æœŸæ”¶ç›Š**ï¼šAPIç®¡ç†æ•ˆç‡æå‡100%
- **é£é™©ç­‰çº§**ï¼šä¸­ç­‰

### ç¬¬ä¸‰é˜¶æ®µCï¼šè®¾è®¡æ¨¡å¼åº”ç”¨ (3-4å¤©)
- **ç›®æ ‡**ï¼šåº”ç”¨3-5ä¸ªè®¾è®¡æ¨¡å¼
- **é¢„æœŸæ”¶ç›Š**ï¼šæ¶æ„è´¨é‡æ˜¾è‘—æå‡
- **é£é™©ç­‰çº§**ï¼šé«˜

### ç¬¬ä¸‰é˜¶æ®µDï¼šæ€§èƒ½ä¼˜åŒ– (1-2å¤©)
- **ç›®æ ‡**ï¼šä¼˜åŒ–{total_perf_issues}ä¸ªæ€§èƒ½é—®é¢˜
- **é¢„æœŸæ”¶ç›Š**ï¼šæ€§èƒ½æå‡15-30%
- **é£é™©ç­‰çº§**ï¼šä½

---

## ğŸ“Š é¢„æœŸæ€»ä½“æ”¶ç›Š

### é‡åŒ–æŒ‡æ ‡
- **ä»£ç å‡å°‘**ï¼š200-300è¡Œ
- **å¤æ‚åº¦é™ä½**ï¼š50-70%
- **æ€§èƒ½æå‡**ï¼š15-30%
- **ç»´æŠ¤æ•ˆç‡**ï¼šæå‡40-60%

### è´¨é‡æå‡
- **å¯è¯»æ€§**ï¼šæ˜¾è‘—æ”¹å–„
- **å¯ç»´æŠ¤æ€§**ï¼šå¤§å¹…æå‡
- **å¯æ‰©å±•æ€§**ï¼šæ˜æ˜¾å¢å¼º
- **æ¶æ„è´¨é‡**ï¼šè´¨çš„é£è·ƒ

---

## ğŸš€ å¼€å§‹æ‰§è¡Œ

å‡†å¤‡å¥½å¼€å§‹ç¬¬ä¸‰é˜¶æ®µæ¶æ„ä¼˜åŒ–äº†å—ï¼Ÿ

å»ºè®®æ‰§è¡Œé¡ºåºï¼š
1. **ç¬¬ä¸‰é˜¶æ®µA**ï¼šå¤æ‚æ–¹æ³•æ‹†åˆ†ï¼ˆé£é™©è¾ƒä½ï¼Œæ”¶ç›Šæ˜æ˜¾ï¼‰
2. **ç¬¬ä¸‰é˜¶æ®µD**ï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆé£é™©æœ€ä½ï¼Œå¯å¹¶è¡Œï¼‰
3. **ç¬¬ä¸‰é˜¶æ®µB**ï¼šAPIç»Ÿä¸€åŒ–ï¼ˆåŸºäºå‰é¢åŸºç¡€ï¼‰
4. **ç¬¬ä¸‰é˜¶æ®µC**ï¼šè®¾è®¡æ¨¡å¼åº”ç”¨ï¼ˆé£é™©æœ€é«˜ï¼Œæœ€åæ‰§è¡Œï¼‰

**ç¬¬ä¸‰é˜¶æ®µæ¶æ„ä¼˜åŒ–åˆ†æå®Œæˆï¼Œå¯ä»¥å¼€å§‹æ‰§è¡Œä¼˜åŒ–å·¥ä½œï¼** ğŸš€
"""

        try:
            with open('ç¬¬ä¸‰é˜¶æ®µæ¶æ„ä¼˜åŒ–åˆ†ææŠ¥å‘Š.md', 'w', encoding='utf-8') as f:
                f.write(report)
            print("âœ… åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸ: ç¬¬ä¸‰é˜¶æ®µæ¶æ„ä¼˜åŒ–åˆ†ææŠ¥å‘Š.md")
        except Exception as e:
            print(f"âŒ åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    optimizer = Phase3ArchitectureOptimizer()

    print("ğŸ¬ PyQt5ç”µå½±ç¥¨åŠ¡ç®¡ç†ç³»ç»Ÿ - ç¬¬ä¸‰é˜¶æ®µæ¶æ„ä¼˜åŒ–")
    print("=" * 70)
    print("ğŸ¯ ç›®æ ‡ï¼šæ·±å±‚æ¬¡æ¶æ„ä¼˜åŒ–ï¼Œæå‡ä»£ç è´¨é‡å’Œæ€§èƒ½")
    print("ğŸ“‹ åŸºç¡€ï¼šç¬¬äºŒé˜¶æ®µ443ä¸ªé‡å¤æ¨¡å¼å·²é‡æ„å®Œæˆ")
    print("âš ï¸ é‡è¦ï¼šåˆ†4ä¸ªå­é˜¶æ®µå®‰å…¨æ‰§è¡Œï¼Œæ¯é˜¶æ®µåå……åˆ†æµ‹è¯•")
    print()

    confirm = input("ç¡®è®¤å¼€å§‹ç¬¬ä¸‰é˜¶æ®µæ¶æ„ä¼˜åŒ–åˆ†æï¼Ÿ(è¾“å…¥ 'yes' ç»§ç»­): ")
    if confirm.lower() == 'yes':
        success = optimizer.run_comprehensive_analysis()
        if success:
            print("\nâœ… ç¬¬ä¸‰é˜¶æ®µåˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹åˆ†ææŠ¥å‘Šåˆ¶å®šæ‰§è¡Œè®¡åˆ’")
        else:
            print("\nâŒ ç¬¬ä¸‰é˜¶æ®µåˆ†æå¤±è´¥ï¼")
    else:
        print("âŒ åˆ†æå·²å–æ¶ˆ")

if __name__ == "__main__":
    main()